{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"논문코드분석.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1qQbLSm79oEf8r9wGCYbSy7S5nUJhyL__","authorship_tag":"ABX9TyPUWEntVIHpsrMU5zAQCChb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ylSd3pN_EVY-"},"source":["#from google.colab import files\r\n","#src = list(files.upload().values())[0]\r\n","#open('file1.py','wb').write(src)\r\n","#import file1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s4PQY8EsLYOK"},"source":["!pip install tensorboardx\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C4EH7a--K_bg"},"source":["import matplotlib.pyplot as plt\r\n","\r\n","#from google.colab import drive\r\n","#drive.mount('/content/gdrive/')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cC_T-7ta4SoC"},"source":["utils"]},{"cell_type":"code","metadata":{"id":"2C_hxfYG4S7r"},"source":["\"\"\"\r\n","    Some handy functions for pytroch model training ...\r\n","\"\"\"\r\n","import torch\r\n","\r\n","\r\n","# Checkpoints\r\n","def save_checkpoint(model, model_dir):\r\n","    torch.save(model.state_dict(), model_dir)\r\n","\r\n","\r\n","def resume_checkpoint(model, model_dir, device_id):\r\n","    state_dict = torch.load(model_dir,\r\n","                            map_location=lambda storage, loc: storage.cuda(device=device_id))  # ensure all storage are on gpu\r\n","    model.load_state_dict(state_dict)\r\n","\r\n","\r\n","# Hyper params\r\n","def use_cuda(enabled, device_id=0):\r\n","    if enabled:\r\n","        assert torch.cuda.is_available(), 'CUDA is not available'\r\n","        torch.cuda.set_device(device_id)\r\n","\r\n","\r\n","def use_optimizer(network, params):\r\n","    if params['optimizer'] == 'sgd':\r\n","        optimizer = torch.optim.SGD(network.parameters(),\r\n","                                    lr=params['sgd_lr'],\r\n","                                    momentum=params['sgd_momentum'],\r\n","                                    weight_decay=params['l2_regularization'])\r\n","    elif params['optimizer'] == 'adam':\r\n","        optimizer = torch.optim.Adam(network.parameters(), \r\n","                                                          lr=params['adam_lr'],\r\n","                                                          weight_decay=params['l2_regularization'])\r\n","    elif params['optimizer'] == 'rmsprop':\r\n","        optimizer = torch.optim.RMSprop(network.parameters(),\r\n","                                        lr=params['rmsprop_lr'],\r\n","                                        alpha=params['rmsprop_alpha'],\r\n","                                        momentum=params['rmsprop_momentum'])\r\n","    return optimizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7jJcOwAV329C"},"source":["metrics"]},{"cell_type":"code","metadata":{"id":"t_NMSUIc33RC"},"source":["import math\r\n","import pandas as pd\r\n","\r\n","\r\n","class MetronAtK(object):\r\n","    def __init__(self, top_k):\r\n","        self._top_k = top_k\r\n","        self._subjects = None  # Subjects which we ran evaluation on\r\n","\r\n","    @property\r\n","    def top_k(self):\r\n","        return self._top_k\r\n","\r\n","    @top_k.setter\r\n","    def top_k(self, top_k):\r\n","        self._top_k = top_k\r\n","\r\n","    @property\r\n","    def subjects(self):\r\n","        return self._subjects\r\n","\r\n","    @subjects.setter\r\n","    def subjects(self, subjects):\r\n","        \"\"\"\r\n","        args:\r\n","            subjects: list, [test_users, test_items, test_scores, negative users, negative items, negative scores]\r\n","        \"\"\"\r\n","        assert isinstance(subjects, list)\r\n","        test_users, test_items, test_scores = subjects[0], subjects[1], subjects[2]\r\n","        neg_users, neg_items, neg_scores = subjects[3], subjects[4], subjects[5]\r\n","        # the golden set\r\n","        test = pd.DataFrame({'user': test_users,\r\n","                             'test_item': test_items,\r\n","                             'test_score': test_scores})\r\n","        # the full set\r\n","        full = pd.DataFrame({'user': neg_users + test_users,\r\n","                            'item': neg_items + test_items,\r\n","                            'score': neg_scores + test_scores})\r\n","        full = pd.merge(full, test, on=['user'], how='left')\r\n","        # rank the items according to the scores for each user\r\n","        full['rank'] = full.groupby('user')['score'].rank(method='first', ascending=False)\r\n","        full.sort_values(['user', 'rank'], inplace=True)\r\n","        self._subjects = full\r\n","\r\n","    def cal_hit_ratio(self):\r\n","        \"\"\"Hit Ratio @ top_K\"\"\"\r\n","        full, top_k = self._subjects, self._top_k\r\n","        top_k = full[full['rank']<=top_k]\r\n","        test_in_top_k =top_k[top_k['test_item'] == top_k['item']]  # golden items hit in the top_K items\r\n","        return len(test_in_top_k) * 1.0 / full['user'].nunique()\r\n","\r\n","    def cal_ndcg(self):\r\n","        full, top_k = self._subjects, self._top_k\r\n","        top_k = full[full['rank']<=top_k]\r\n","        test_in_top_k =top_k[top_k['test_item'] == top_k['item']]\r\n","        test_in_top_k['ndcg'] = test_in_top_k['rank'].apply(lambda x: math.log(2) / math.log(1 + x)) # the rank starts from 1\r\n","        return test_in_top_k['ndcg'].sum() * 1.0 / full['user'].nunique()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cf9lpqgg3OV5"},"source":["data.py"]},{"cell_type":"code","metadata":{"id":"MI5I1wZb3L4e"},"source":["import torch\r\n","import random\r\n","import pandas as pd\r\n","from copy import deepcopy\r\n","from torch.utils.data import DataLoader, Dataset\r\n","\r\n","random.seed(0)\r\n","\r\n","\r\n","class UserItemRatingDataset(Dataset):\r\n","    \"\"\"Wrapper, convert <user, item, rating> Tensor into Pytorch Dataset\"\"\"\r\n","    def __init__(self, user_tensor, item_tensor, target_tensor):\r\n","        \"\"\"\r\n","        args:\r\n","\r\n","            target_tensor: torch.Tensor, the corresponding rating for <user, item> pair\r\n","        \"\"\"\r\n","        self.user_tensor = user_tensor\r\n","        self.item_tensor = item_tensor\r\n","        self.target_tensor = target_tensor\r\n","\r\n","    def __getitem__(self, index):\r\n","        return self.user_tensor[index], self.item_tensor[index], self.target_tensor[index]\r\n","\r\n","    def __len__(self):\r\n","        return self.user_tensor.size(0)\r\n","\r\n","\r\n","class SampleGenerator(object):\r\n","    \"\"\"Construct dataset for NCF\"\"\"\r\n","\r\n","    def __init__(self, ratings):\r\n","        \"\"\"\r\n","        args:\r\n","            ratings: pd.DataFrame, which contains 4 columns = ['userId', 'itemId', 'rating', 'timestamp']\r\n","        \"\"\"\r\n","        assert 'userId' in ratings.columns\r\n","        assert 'itemId' in ratings.columns\r\n","        assert 'rating' in ratings.columns\r\n","\r\n","        self.ratings = ratings\r\n","        # explicit feedback using _normalize and implicit using _binarize\r\n","        # self.preprocess_ratings = self._normalize(ratings)\r\n","        self.preprocess_ratings = self._binarize(ratings)\r\n","        self.user_pool = set(self.ratings['userId'].unique())\r\n","        self.item_pool = set(self.ratings['itemId'].unique())\r\n","        # create negative item samples for NCF learning\r\n","        self.negatives = self._sample_negative(ratings)\r\n","        self.train_ratings, self.test_ratings = self._split_loo(self.preprocess_ratings)\r\n","        \r\n","    def _normalize(self, ratings):\r\n","        \"\"\"normalize into [0, 1] from [0, max_rating], explicit feedback\"\"\"\r\n","        ratings = deepcopy(ratings)\r\n","        max_rating = ratings.rating.max()\r\n","        ratings['rating'] = ratings.rating * 1.0 / max_rating\r\n","        return ratings\r\n","    \r\n","    def _binarize(self, ratings):\r\n","        \"\"\"binarize into 0 or 1, imlicit feedback\"\"\"\r\n","        ratings = deepcopy(ratings)\r\n","        ratings['rating'][ratings['rating'] > 0] = 1.0\r\n","        return ratings\r\n","\r\n","    def _split_loo(self, ratings):\r\n","        \"\"\"leave one out train/test split \"\"\"\r\n","        ratings['rank_latest'] = ratings.groupby(['userId'])['timestamp'].rank(method='first', ascending=False)\r\n","        test = ratings[ratings['rank_latest'] == 1]\r\n","        train = ratings[ratings['rank_latest'] > 1]\r\n","        assert train['userId'].nunique() == test['userId'].nunique()\r\n","        return train[['userId', 'itemId', 'rating']], test[['userId', 'itemId', 'rating']]\r\n","\r\n","    def _sample_negative(self, ratings):\r\n","        \"\"\"return all negative items & 100 sampled negative items\"\"\"\r\n","        interact_status = ratings.groupby('userId')['itemId'].apply(set).reset_index().rename(\r\n","            columns={'itemId': 'interacted_items'})\r\n","        interact_status['negative_items'] = interact_status['interacted_items'].apply(lambda x: self.item_pool - x)\r\n","        interact_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, 99))\r\n","        return interact_status[['userId', 'negative_items', 'negative_samples']]\r\n","\r\n","    def instance_a_train_loader(self, num_negatives, batch_size):\r\n","        \"\"\"instance train loader for one training epoch\"\"\"\r\n","        users, items, ratings = [], [], []\r\n","        train_ratings = pd.merge(self.train_ratings, self.negatives[['userId', 'negative_items']], on='userId')\r\n","        train_ratings['negatives'] = train_ratings['negative_items'].apply(lambda x: random.sample(x, num_negatives))\r\n","        for row in train_ratings.itertuples():\r\n","            users.append(int(row.userId))\r\n","            items.append(int(row.itemId))\r\n","            ratings.append(float(row.rating))\r\n","            for i in range(num_negatives):\r\n","                users.append(int(row.userId))\r\n","                items.append(int(row.negatives[i]))\r\n","                ratings.append(float(0))  # negative samples get 0 rating\r\n","        dataset = UserItemRatingDataset(user_tensor=torch.LongTensor(users),\r\n","                                        item_tensor=torch.LongTensor(items),\r\n","                                        target_tensor=torch.FloatTensor(ratings))\r\n","        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\r\n","\r\n","    @property\r\n","    def evaluate_data(self):\r\n","        \"\"\"create evaluate data\"\"\"\r\n","        test_ratings = pd.merge(self.test_ratings, self.negatives[['userId', 'negative_samples']], on='userId')\r\n","        test_users, test_items, negative_users, negative_items = [], [], [], []\r\n","        for row in test_ratings.itertuples():\r\n","            test_users.append(int(row.userId))\r\n","            test_items.append(int(row.itemId))\r\n","            for i in range(len(row.negative_samples)):\r\n","                negative_users.append(int(row.userId))\r\n","                negative_items.append(int(row.negative_samples[i]))\r\n","        return [torch.LongTensor(test_users), torch.LongTensor(test_items), torch.LongTensor(negative_users),\r\n","                torch.LongTensor(negative_items)]\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lbASjyppb41s"},"source":["use grepp data"]},{"cell_type":"code","metadata":{"id":"_lDfI14Jb35H"},"source":["import torch\r\n","import random\r\n","import pandas as pd\r\n","from copy import deepcopy\r\n","from torch.utils.data import DataLoader, Dataset\r\n","\r\n","random.seed(0)\r\n","\r\n","\r\n","class UserItemRatingDataset(Dataset):\r\n","    \"\"\"Wrapper, convert <user, item, rating> Tensor into Pytorch Dataset\"\"\"\r\n","    def __init__(self, user_tensor, item_tensor, target_tensor):\r\n","        \"\"\"\r\n","        args:\r\n","\r\n","            target_tensor: torch.Tensor, the corresponding rating for <user, item> pair\r\n","        \"\"\"\r\n","        self.user_tensor = user_tensor\r\n","        self.item_tensor = item_tensor\r\n","        self.target_tensor = target_tensor\r\n","\r\n","    def __getitem__(self, index):\r\n","        return self.user_tensor[index], self.item_tensor[index], self.target_tensor[index]\r\n","\r\n","    def __len__(self):\r\n","        return self.user_tensor.size(0)\r\n","\r\n","\r\n","class SampleGenerator(object):\r\n","    \"\"\"Construct dataset for NCF\"\"\"\r\n","\r\n","    def __init__(self, ratings):\r\n","        \"\"\"\r\n","        args:\r\n","            ratings: pd.DataFrame, which contains 4 columns = ['userId', 'itemId', 'rating']\r\n","        \"\"\"\r\n","        assert 'userId' in ratings.columns\r\n","        assert 'itemId' in ratings.columns\r\n","        assert 'rating' in ratings.columns\r\n","\r\n","        self.ratings = ratings\r\n","        # explicit feedback using _normalize and implicit using _binarize\r\n","        # self.preprocess_ratings = self._normalize(ratings)\r\n","        self.preprocess_ratings = self._binarize(ratings)\r\n","        self.user_pool = set(self.ratings['userId'].unique())\r\n","        self.item_pool = set(self.ratings['itemId'].unique())\r\n","        # create negative item samples for NCF learning\r\n","        self.negatives = self._sample_negative(ratings)\r\n","        self.train_ratings, self.test_ratings = self._split_loo(self.preprocess_ratings)\r\n","        self.test = deepcopy(self.test_ratings)\r\n","        self.test.update(ratings)\r\n","\r\n","    def _normalize(self, ratings):\r\n","        \"\"\"normalize into [0, 1] from [0, max_rating], explicit feedback\"\"\"\r\n","        ratings = deepcopy(ratings)\r\n","#        max_rating = ratings.rating.max()\r\n","#        ratings['rating'] = ratings.rating * 1.0 / max_rating\r\n","        return ratings\r\n","    \r\n","    def _binarize(self, ratings):\r\n","        \"\"\"binarize into 0 or 1, imlicit feedback\"\"\"\r\n","        ratings = deepcopy(ratings)\r\n","        ratings['rating'] = 1.0\r\n","        return ratings\r\n","\r\n","    def _split_loo(self, ratings):\r\n","        \"\"\"leave one out train/test split \"\"\"\r\n","        ratings['rank_latest'] = ratings.groupby(['userId']).rank(method='first', ascending=False).rating\r\n","        test = ratings[ratings['rank_latest'] == 1]\r\n","        train = ratings[ratings['rank_latest'] > 1]\r\n","        assert train['userId'].nunique() == test['userId'].nunique()\r\n","        return train[['userId', 'itemId', 'rating']], test[['userId', 'itemId', 'rating']]\r\n","\r\n","    def _sample_negative(self, ratings):\r\n","        \"\"\"return all negative items & 100 sampled negative items\"\"\"\r\n","        interact_status = ratings.groupby('userId')['itemId'].apply(set).reset_index().rename(\r\n","            columns={'itemId': 'interacted_items'})\r\n","        interact_status['negative_items'] = interact_status['interacted_items'].apply(lambda x: self.item_pool - x)\r\n","        interact_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, 99))\r\n","        return interact_status[['userId', 'negative_items', 'negative_samples']]\r\n","\r\n","    def instance_a_train_loader(self, num_negatives, batch_size):\r\n","        \"\"\"instance train loader for one training epoch\"\"\"\r\n","        users, items, ratings = [], [], []\r\n","        train_ratings = pd.merge(self.train_ratings, self.negatives[['userId', 'negative_items']], on='userId')\r\n","        train_ratings['negatives'] = train_ratings['negative_items'].apply(lambda x: random.sample(x, num_negatives))\r\n","        for row in train_ratings.itertuples():\r\n","            users.append(int(row.userId))\r\n","            items.append(int(row.itemId))\r\n","            ratings.append(float(row.rating))\r\n","            for i in range(num_negatives):\r\n","                users.append(int(row.userId))\r\n","                items.append(int(row.negatives[i]))\r\n","                ratings.append(float(0))  # negative samples get 0 rating\r\n","        dataset = UserItemRatingDataset(user_tensor=torch.LongTensor(users),\r\n","                                        item_tensor=torch.LongTensor(items),\r\n","                                        target_tensor=torch.FloatTensor(ratings))\r\n","        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\r\n","\r\n","#####################################################\r\n","    def instance_a_test_loader(self, batch_size):\r\n","        users, jobs, applieds = [], [], []\r\n","        for row in self.test.itertuples():\r\n","            users.append(int(row.userId))\r\n","            jobs.append(int(row.itemId))\r\n","            applieds.append(float(row.rating))\r\n","\r\n","        dataset = UserItemRatingDataset(user_tensor=torch.LongTensor(users),\r\n","                                        item_tensor=torch.LongTensor(jobs),\r\n","                                        target_tensor=torch.FloatTensor(applieds))\r\n","        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\r\n","####################################################\r\n","\r\n","    @property\r\n","    def evaluate_data(self):\r\n","        \"\"\"create evaluate data\"\"\"\r\n","        test_ratings = pd.merge(self.test_ratings, self.negatives[['userId', 'negative_samples']], on='userId')\r\n","        test_users, test_items, negative_users, negative_items = [], [], [], []\r\n","        for row in test_ratings.itertuples():\r\n","            test_users.append(int(row.userId))\r\n","            test_items.append(int(row.itemId))\r\n","            for i in range(len(row.negative_samples)):\r\n","                negative_users.append(int(row.userId))\r\n","                negative_items.append(int(row.negative_samples[i]))\r\n","        return [torch.LongTensor(test_users), torch.LongTensor(test_items), torch.LongTensor(negative_users),\r\n","                torch.LongTensor(negative_items)]\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LOR-K4pv3Rvm"},"source":["engine"]},{"cell_type":"code","metadata":{"id":"T7Y9Z5-03SEe"},"source":["import torch\r\n","from torch.autograd import Variable\r\n","from tensorboardX import SummaryWriter\r\n","\r\n","class Engine(object):\r\n","    \"\"\"Meta Engine for training & evaluating NCF model\r\n","\r\n","    Note: Subclass should implement self.model !\r\n","    \"\"\"\r\n","\r\n","    def __init__(self, config):\r\n","        self.config = config  # model configuration\r\n","        self._metron = MetronAtK(top_k=10)\r\n","        self._writer = SummaryWriter(log_dir='runs/{}'.format(config['alias']))  # tensorboard writer\r\n","        self._writer.add_text('config', str(config), 0)\r\n","        self.opt = use_optimizer(self.model, config)\r\n","        # explicit feedback\r\n","        # self.crit = torch.nn.MSELoss()\r\n","        # implicit feedback\r\n","        self.crit = torch.nn.BCELoss()\r\n","\r\n","    def train_single_batch(self, users, items, ratings):\r\n","        assert hasattr(self, 'model'), 'Please specify the exact model !'\r\n","        if self.config['use_cuda'] is True:\r\n","            users, items, ratings = users.cuda(), items.cuda(), ratings.cuda()\r\n","        self.opt.zero_grad()\r\n","        ratings_pred = self.model(users, items)\r\n","        loss = self.crit(ratings_pred.view(-1), ratings)\r\n","        loss.backward()\r\n","        self.opt.step()\r\n","        loss = loss.item()\r\n","        return loss\r\n","\r\n","    def train_an_epoch(self, train_loader, epoch_id):\r\n","        assert hasattr(self, 'model'), 'Please specify the exact model !'\r\n","        self.model.train()\r\n","        total_loss = 0\r\n","        for batch_id, batch in enumerate(train_loader):\r\n","            assert isinstance(batch[0], torch.LongTensor)\r\n","            user, item, rating = batch[0], batch[1], batch[2]\r\n","            rating = rating.float()\r\n","            loss = self.train_single_batch(user, item, rating)\r\n","            print('[Training Epoch {}] Batch {}, Loss {}'.format(epoch_id, batch_id, loss))\r\n","            total_loss += loss\r\n","        self._writer.add_scalar('model/loss', total_loss, epoch_id)\r\n","\r\n","    def evaluate(self, evaluate_data, epoch_id):\r\n","        assert hasattr(self, 'model'), 'Please specify the exact model !'\r\n","        self.model.eval()\r\n","        with torch.no_grad():\r\n","            test_users, test_items = evaluate_data[0], evaluate_data[1]\r\n","            negative_users, negative_items = evaluate_data[2], evaluate_data[3]\r\n","            if self.config['use_cuda'] is True:\r\n","                test_users = test_users.cuda()\r\n","                test_items = test_items.cuda()\r\n","                negative_users = negative_users.cuda()\r\n","                negative_items = negative_items.cuda()\r\n","            test_scores = self.model(test_users, test_items)\r\n","            negative_scores = self.model(negative_users, negative_items)\r\n","            if self.config['use_cuda'] is True:\r\n","                test_users = test_users.cpu()\r\n","                test_items = test_items.cpu()\r\n","                test_scores = test_scores.cpu()\r\n","                negative_users = negative_users.cpu()\r\n","                negative_items = negative_items.cpu()\r\n","                negative_scores = negative_scores.cpu()\r\n","            self._metron.subjects = [test_users.data.view(-1).tolist(),\r\n","                                 test_items.data.view(-1).tolist(),\r\n","                                 test_scores.data.view(-1).tolist(),\r\n","                                 negative_users.data.view(-1).tolist(),\r\n","                                 negative_items.data.view(-1).tolist(),\r\n","                                 negative_scores.data.view(-1).tolist()]\r\n","        hit_ratio, ndcg = self._metron.cal_hit_ratio(), self._metron.cal_ndcg()\r\n","        self._writer.add_scalar('performance/HR', hit_ratio, epoch_id)\r\n","        self._writer.add_scalar('performance/NDCG', ndcg, epoch_id)\r\n","        print('[Evluating Epoch {}] HR = {:.4f}, NDCG = {:.4f}'.format(epoch_id, hit_ratio, ndcg))\r\n","        return hit_ratio, ndcg\r\n","\r\n","    def save(self, alias, epoch_id, hit_ratio, ndcg):\r\n","        assert hasattr(self, 'model'), 'Please specify the exact model !'\r\n","        model_dir = self.config['model_dir'].format(alias, epoch_id, hit_ratio, ndcg)\r\n","        save_checkpoint(self.model, model_dir)\r\n","\r\n","    def eval_data(self, evaluate_data, epoch_id):\r\n","        assert hasattr(self, 'model'), 'Please specify the exact model !'\r\n","        self.model.eval()\r\n","        with torch.no_grad():\r\n","            test_users, test_items = evaluate_data[0], evaluate_data[1]\r\n","            test_labels = evaluate_data[2]\r\n","            if self.config['use_cuda'] is True:\r\n","                test_users = test_users.cuda()\r\n","                test_items = test_items.cuda()\r\n","            test_scores = self.model(test_users, test_items)\r\n","            if self.config['use_cuda'] is True:\r\n","                test_users = test_users.cpu()\r\n","                test_items = test_items.cpu()\r\n","                test_scores = test_scores.cpu()\r\n","            \r\n","#        print('[Evluating Epoch {}] HR = {:.4f}, NDCG = {:.4f}'.format(epoch_id, hit_ratio, ndcg))\r\n","        return test_scores, test_labels\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xD1GK-LP318y"},"source":["gmf"]},{"cell_type":"code","metadata":{"id":"Pt9vNkrK3mFO"},"source":["import torch\r\n","\r\n","class GMF(torch.nn.Module):\r\n","    def __init__(self, config):\r\n","        super(GMF, self).__init__()\r\n","        self.num_users = config['num_users']\r\n","        self.num_items = config['num_items']\r\n","        self.latent_dim = config['latent_dim']\r\n","\r\n","        self.embedding_user = torch.nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.latent_dim)\r\n","        self.embedding_item = torch.nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.latent_dim)\r\n","\r\n","        self.affine_output = torch.nn.Linear(in_features=self.latent_dim, out_features=1)\r\n","        self.logistic = torch.nn.Sigmoid()\r\n","\r\n","    def forward(self, user_indices, item_indices):\r\n","        user_embedding = self.embedding_user(user_indices)\r\n","        item_embedding = self.embedding_item(item_indices)\r\n","        element_product = torch.mul(user_embedding, item_embedding)\r\n","        logits = self.affine_output(element_product)\r\n","        rating = self.logistic(logits)\r\n","        return rating\r\n","\r\n","    def init_weight(self):\r\n","        pass\r\n","\r\n","\r\n","class GMFEngine(Engine):\r\n","    \"\"\"Engine for training & evaluating GMF model\"\"\"\r\n","    def __init__(self, config):\r\n","        self.model = GMF(config)\r\n","        if config['use_cuda'] is True:\r\n","            use_cuda(True, config['device_id'])\r\n","            self.model.cuda()\r\n","        super(GMFEngine, self).__init__(config)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d4YDvJd438ku"},"source":["mlp"]},{"cell_type":"code","metadata":{"id":"SIzyZCSF380i"},"source":["import torch\r\n","\r\n","class MLP(torch.nn.Module):\r\n","    def __init__(self, config):\r\n","        super(MLP, self).__init__()\r\n","        self.config = config\r\n","        self.num_users = config['num_users']\r\n","        self.num_items = config['num_items']\r\n","        self.latent_dim = config['latent_dim']\r\n","\r\n","        self.embedding_user = torch.nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.latent_dim)\r\n","        self.embedding_item = torch.nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.latent_dim)\r\n","\r\n","        self.fc_layers = torch.nn.ModuleList()\r\n","        for idx, (in_size, out_size) in enumerate(zip(config['layers'][:-1], config['layers'][1:])):\r\n","            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\r\n","\r\n","        self.affine_output = torch.nn.Linear(in_features=config['layers'][-1], out_features=1)\r\n","        self.logistic = torch.nn.Sigmoid()\r\n","\r\n","    def forward(self, user_indices, item_indices):\r\n","        user_embedding = self.embedding_user(user_indices)\r\n","        item_embedding = self.embedding_item(item_indices)\r\n","        vector = torch.cat([user_embedding, item_embedding], dim=-1)  # the concat latent vector\r\n","        for idx, _ in enumerate(range(len(self.fc_layers))):\r\n","            vector = self.fc_layers[idx](vector)\r\n","            vector = torch.nn.ReLU()(vector)\r\n","            # vector = torch.nn.BatchNorm1d()(vector)\r\n","            # vector = torch.nn.Dropout(p=0.5)(vector)\r\n","        logits = self.affine_output(vector)\r\n","        rating = self.logistic(logits)\r\n","        return rating\r\n","\r\n","    def init_weight(self):\r\n","        pass\r\n","\r\n","    def load_pretrain_weights(self):\r\n","        \"\"\"Loading weights from trained GMF model\"\"\"\r\n","        config = self.config\r\n","        gmf_model = GMF(config)\r\n","        if config['use_cuda'] is True:\r\n","            gmf_model.cuda()\r\n","        resume_checkpoint(gmf_model, model_dir=config['pretrain_mf'], device_id=config['device_id'])\r\n","        self.embedding_user.weight.data = gmf_model.embedding_user.weight.data\r\n","        self.embedding_item.weight.data = gmf_model.embedding_item.weight.data\r\n","\r\n","\r\n","class MLPEngine(Engine):\r\n","    \"\"\"Engine for training & evaluating GMF model\"\"\"\r\n","    def __init__(self, config):\r\n","        self.model = MLP(config)\r\n","        if config['use_cuda'] is True:\r\n","            use_cuda(True, config['device_id'])\r\n","            self.model.cuda()\r\n","        super(MLPEngine, self).__init__(config)\r\n","        print(self.model)\r\n","\r\n","        if config['pretrain']:\r\n","            self.model.load_pretrain_weights()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HHBk2v5D4JHb"},"source":["neumf"]},{"cell_type":"code","metadata":{"id":"Za73fhvf4Jax"},"source":["import torch\r\n","\r\n","class NeuMF(torch.nn.Module):\r\n","    def __init__(self, config):\r\n","        super(NeuMF, self).__init__()\r\n","        self.config = config\r\n","        self.num_users = config['num_users']\r\n","        self.num_items = config['num_items']\r\n","        self.latent_dim_mf = config['latent_dim_mf']\r\n","        self.latent_dim_mlp = config['latent_dim_mlp']\r\n","\r\n","        self.embedding_user_mlp = torch.nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.latent_dim_mlp)\r\n","        self.embedding_item_mlp = torch.nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.latent_dim_mlp)\r\n","        self.embedding_user_mf = torch.nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.latent_dim_mf)\r\n","        self.embedding_item_mf = torch.nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.latent_dim_mf)\r\n","\r\n","        self.fc_layers = torch.nn.ModuleList()\r\n","        for idx, (in_size, out_size) in enumerate(zip(config['layers'][:-1], config['layers'][1:])):\r\n","            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\r\n","\r\n","        self.affine_output = torch.nn.Linear(in_features=config['layers'][-1] + config['latent_dim_mf'], out_features=1)\r\n","        self.logistic = torch.nn.Sigmoid()\r\n","\r\n","    def forward(self, user_indices, item_indices):\r\n","        user_embedding_mlp = self.embedding_user_mlp(user_indices)\r\n","        item_embedding_mlp = self.embedding_item_mlp(item_indices)\r\n","        user_embedding_mf = self.embedding_user_mf(user_indices)\r\n","        item_embedding_mf = self.embedding_item_mf(item_indices)\r\n","\r\n","        mlp_vector = torch.cat([user_embedding_mlp, item_embedding_mlp], dim=-1)  # the concat latent vector\r\n","        mf_vector =torch.mul(user_embedding_mf, item_embedding_mf)\r\n","\r\n","        for idx, _ in enumerate(range(len(self.fc_layers))):\r\n","            mlp_vector = self.fc_layers[idx](mlp_vector)\r\n","            mlp_vector = torch.nn.ReLU()(mlp_vector)\r\n","\r\n","        vector = torch.cat([mlp_vector, mf_vector], dim=-1)\r\n","        logits = self.affine_output(vector)\r\n","        rating = self.logistic(logits)\r\n","        return rating\r\n","\r\n","    def init_weight(self):\r\n","        pass\r\n","\r\n","    def load_pretrain_weights(self):\r\n","        \"\"\"Loading weights from trained MLP model & GMF model\"\"\"\r\n","        config = self.config\r\n","        config['latent_dim'] = config['latent_dim_mlp']\r\n","        mlp_model = MLP(config)\r\n","        if config['use_cuda'] is True:\r\n","            mlp_model.cuda()\r\n","        resume_checkpoint(mlp_model, model_dir=config['pretrain_mlp'], device_id=config['device_id'])\r\n","\r\n","        self.embedding_user_mlp.weight.data = mlp_model.embedding_user.weight.data\r\n","        self.embedding_item_mlp.weight.data = mlp_model.embedding_item.weight.data\r\n","        for idx in range(len(self.fc_layers)):\r\n","            self.fc_layers[idx].weight.data = mlp_model.fc_layers[idx].weight.data\r\n","\r\n","        config['latent_dim'] = config['latent_dim_mf']\r\n","        gmf_model = GMF(config)\r\n","        if config['use_cuda'] is True:\r\n","            gmf_model.cuda()\r\n","        resume_checkpoint(gmf_model, model_dir=config['pretrain_mf'], device_id=config['device_id'])\r\n","        self.embedding_user_mf.weight.data = gmf_model.embedding_user.weight.data\r\n","        self.embedding_item_mf.weight.data = gmf_model.embedding_item.weight.data\r\n","\r\n","        self.affine_output.weight.data = 0.5 * torch.cat([mlp_model.affine_output.weight.data, gmf_model.affine_output.weight.data], dim=-1)\r\n","        self.affine_output.bias.data = 0.5 * (mlp_model.affine_output.bias.data + gmf_model.affine_output.bias.data)\r\n","\r\n","\r\n","class NeuMFEngine(Engine):\r\n","    \"\"\"Engine for training & evaluating GMF model\"\"\"\r\n","    def __init__(self, config):\r\n","        self.model = NeuMF(config)\r\n","        if config['use_cuda'] is True:\r\n","            use_cuda(True, config['device_id'])\r\n","            self.model.cuda()\r\n","        super(NeuMFEngine, self).__init__(config)\r\n","        print(self.model)\r\n","\r\n","        if config['pretrain']:\r\n","            self.model.load_pretrain_weights()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zru5BtA84seH"},"source":["train"]},{"cell_type":"code","metadata":{"id":"MCBEog_44M8X"},"source":["import pandas as pd\r\n","import numpy as np\r\n","#from gmf import GMFEngine\r\n","#from mlp import MLPEngine\r\n","#from neumf import NeuMFEngine\r\n","#from data import SampleGenerator\r\n","\r\n","gmf_config = {'alias': 'gmf_factor8neg4-implict',\r\n","              'num_epoch': 20,\r\n","              'batch_size': 256,\r\n","              # 'optimizer': 'sgd',\r\n","              # 'sgd_lr': 1e-3,\r\n","              # 'sgd_momentum': 0.9,\r\n","              # 'optimizer': 'rmsprop',\r\n","              # 'rmsprop_lr': 1e-3,\r\n","              # 'rmsprop_alpha': 0.99,\r\n","              # 'rmsprop_momentum': 0,\r\n","              'optimizer': 'adam',\r\n","              'adam_lr': 1e-2,\r\n","              'num_users': 196,\r\n","              'num_items': 708,\r\n","              'latent_dim': 10,\r\n","              'num_negative': 8,\r\n","              'l2_regularization': 0, # 0.01\r\n","              'use_cuda': True,\r\n","              'device_id': 0,\r\n","              'model_dir':'drive/MyDrive/colab/checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'}\r\n","\r\n","mlp_config = {'alias': 'mlp_factor8neg4_bz256_166432168_pretrain_reg_0.0000001',\r\n","              'num_epoch': 30,\r\n","              'batch_size': 256,  # 1024,\r\n","              'optimizer': 'adam',\r\n","              'adam_lr': 1e-3,\r\n","              'num_users': 196,\r\n","              'num_items': 708,\r\n","              'latent_dim': 10,\r\n","              'num_negative': 8,\r\n","              'layers': [16,64,32,16,8],  # layers[0] is the concat of latent user vector & latent item vector\r\n","              'l2_regularization': 0.0000001,  # MLP model is sensitive to hyper params\r\n","              'use_cuda': True,\r\n","              'device_id': 0,\r\n","              'pretrain': False,\r\n","              'pretrain_mf': 'drive/MyDrive/colab/checkpoints/{}'.format('gmf_factor8neg4_Epoch100_HR0.6391_NDCG0.2852.model'),\r\n","              'model_dir':'drive/MyDrive/colab/checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'}\r\n","\r\n","neumf_config = {'alias': 'pretrain_neumf_factor8neg4',\r\n","                'num_epoch': 20,\r\n","                'batch_size': 1024,\r\n","                'optimizer': 'adam',\r\n","                'adam_lr': 1e-3,\r\n","                'num_users': 6040,\r\n","                'num_items': 3706,\r\n","                'latent_dim_mf': 8,\r\n","                'latent_dim_mlp': 8,\r\n","                'num_negative': 4,\r\n","                'layers': [16,32,16,8],  # layers[0] is the concat of latent user vector & latent item vector\r\n","                'l2_regularization': 0.01,\r\n","                'use_cuda': True,\r\n","                'device_id': 0,\r\n","                'pretrain': False,\r\n","                'pretrain_mf': 'drive/MyDrive/colab/checkpoints/{}'.format('gmf_factor8neg4_Epoch100_HR0.6391_NDCG0.2852.model'),\r\n","                'pretrain_mlp': 'drive/MyDrive/colab/checkpoints/{}'.format('mlp_factor8neg4_Epoch100_HR0.5606_NDCG0.2463.model'),\r\n","                'model_dir':'drive/MyDrive/colab/checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'\r\n","                }\r\n","\r\n","# Load Data\r\n","\r\n","#############################################################################\r\n","#ml1m_dir = 'drive/MyDrive/colab/mvlm/ratings.dat'\r\n","#ml1m_rating = pd.read_csv(ml1m_dir, sep='::', header=None, names=['uid', 'mid', 'rating', 'timestamp'],  engine='python')\r\n","#############################################################################\r\n","\r\n","ml1m_dir = 'drive/MyDrive/colab/train_job/train.csv'\r\n","ml1m_rating = pd.read_csv(ml1m_dir, names=['uid', 'mid', 'rating'],  engine='python', skiprows = [0])  # 첫째줄 헤더 제거\r\n","print(ml1m_rating)\r\n","# Reindex\r\n","user_id = ml1m_rating[['uid']].drop_duplicates().reindex()\r\n","user_id['userId'] = np.arange(len(user_id))\r\n","ml1m_rating = pd.merge(ml1m_rating, user_id, on=['uid'], how='left')\r\n","item_id = ml1m_rating[['mid']].drop_duplicates()\r\n","item_id['itemId'] = np.arange(len(item_id))\r\n","ml1m_rating = pd.merge(ml1m_rating, item_id, on=['mid'], how='left')\r\n","\r\n","#############################################################################\r\n","#ml1m_rating = ml1m_rating[['userId', 'itemId', 'rating', 'timestamp']]\r\n","#############################################################################\r\n","\r\n","ml1m_rating = ml1m_rating[['userId', 'itemId', 'rating']]\r\n","\r\n","print('Range of userId is [{}, {}]'.format(ml1m_rating.userId.min(), ml1m_rating.userId.max()))\r\n","print('Range of itemId is [{}, {}]'.format(ml1m_rating.itemId.min(), ml1m_rating.itemId.max()))\r\n","# DataLoader for training\r\n","sample_generator = SampleGenerator(ratings=ml1m_rating)\r\n","evaluate_data = sample_generator.evaluate_data\r\n","# Specify the exact model\r\n","config = gmf_config\r\n","engine = GMFEngine(config)\r\n","#config = mlp_config\r\n","#engine = MLPEngine(config)\r\n","#config = neumf_config\r\n","#engine = NeuMFEngine(config)\r\n","hit_ratios = []\r\n","ndcgs = []\r\n","for epoch in range(config['num_epoch']):\r\n","    print('Epoch {} starts !'.format(epoch))\r\n","    print('-' * 80)\r\n","    train_loader = sample_generator.instance_a_train_loader(config['num_negative'], config['batch_size'])\r\n","    engine.train_an_epoch(train_loader, epoch_id=epoch)\r\n","    hit_ratio, ndcg = engine.evaluate(evaluate_data, epoch_id=epoch)\r\n","    hit_ratios.append(hit_ratio)\r\n","    ndcgs.append(ndcg)\r\n","    engine.save(config['alias'], epoch, hit_ratio, ndcg)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v6ZGBRhXTObS"},"source":["hit_ratios \r\n","ndcgs\r\n","description = \"lr : \" + str(config['adam_lr']) + \"  latent_dim : \" + str(config['latent_dim']) + \"  num_negative : \" + str(config['num_negative'])\r\n","plt.figure(figsize=(8.0, 6.0))\r\n","plt.title(description)\r\n","plt.xlabel(\"eps\")\r\n","plt.ylabel(\"accracy\")\r\n","plt.plot(range(config['num_epoch']), hit_ratios, label=\"hit_ratios\")\r\n","plt.plot(range(config['num_epoch']), ndcgs, label=\"ndcgs\")\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kOv31ttVwg30"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lul08oOf31cw"},"source":["test_data = sample_generator.instance_a_test_loader(config['batch_size'])\r\n","predict, label = engine.eval_data(next(iter(test_data)), epoch_id=epoch)\r\n","predict = predict.T[0]\r\n","#print(predict)\r\n","#print(predict - label)\r\n","correct = 0\r\n","for i in range(len(predict)):\r\n","    if predict[i] > 0.5:\r\n","        predict[i] = 1\r\n","    else: predict[i] = 0\r\n","    if predict[i] == label[i]:\r\n","        correct +=1\r\n","print(\"applied count : \", int(sum(label)))\r\n","print(\"applied rate : \", float(sum(label))/ len(label))\r\n","print(\"eps : \", config['num_epoch'])\r\n","print(\"lr : \", config['adam_lr'])\r\n","print(\"latent_dim : \", config['latent_dim'])\r\n","print('num_negative : ', config['num_negative'])\r\n","print('total : ', len(predict))\r\n","print('correct : ', correct)\r\n","print(\"accuracy : \", correct/len(predict))"],"execution_count":null,"outputs":[]}]}